# Supply Chain Intelligence Demo

A demonstration application showcasing **OpenAI GPT-OSS-20B** for intelligent supply chain analysis and decision-making.

## ğŸ¯ Features

- **ğŸ¤– OpenAI GPT-OSS-20B Integration**: Uses the latest 20B parameter open-source model from OpenAI
- **ğŸšš Supply Chain Analytics**: Inventory management, delivery tracking, and supplier analysis
- **ğŸ“Š Interactive Visualizations**: Real-time charts and metrics with Plotly
- **âš¡ Local AI Inference**: Runs entirely on your machine via Ollama
- **ğŸ”„ Streaming Responses**: Progressive text generation for better user experience
- **ğŸ“‹ Actionable Insights**: AI-powered recommendations with fallback rule-based analysis

## ğŸ›  Technology Stack

- **AI Model**: OpenAI GPT-OSS-20B (20.9B parameters, MXFP4 quantized)
- **Runtime**: Ollama (local inference engine)
- **Frontend**: Streamlit (interactive web interface)
- **Data**: Pandas (supply chain data processing)
- **Visualizations**: Plotly (interactive charts)
- **Language**: Python 3.12+

## ğŸš€ Quick Start

### Prerequisites

1. **Install Ollama** (for running GPT-OSS locally):
   ```bash
   brew install ollama
   brew services start ollama
   ```

2. **Pull the GPT-OSS-20B model**:
   ```bash
   ollama pull gpt-oss:20b
   ```
   *Note: This will download ~13GB and may take some time*

### Setup & Launch

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd oss-toy
   chmod +x run.sh
   ./run.sh
   ```

2. **Or manual setup**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   streamlit run app.py
   ```

3. **Open your browser**: http://localhost:8501

## ğŸ“– Usage

1. **Load the AI Model**: Click "ğŸš€ Load OpenAI GPT-OSS-20B" in the sidebar
2. **Ask Questions**: Enter supply chain queries like:
   - "Which items need restocking?"
   - "What are the delivery delays?"
   - "Analyze supplier performance"
   - "Optimize warehouse utilization"
3. **Get AI Insights**: View streaming responses with actionable recommendations
4. **Apply Actions**: Use suggested actions to modify data (simulation)

## ğŸ”§ Model Performance

- **Model Size**: 20.9B parameters (13GB download)
- **Quantization**: Native MXFP4 for efficiency
- **Memory**: Runs in ~16GB RAM
- **Speed**: ~5-15 seconds per response (CPU dependent)
- **Quality**: Advanced reasoning and context understanding

## ğŸ— Architecture

```
User Query â†’ Streamlit UI â†’ Supply Chain Data â†’ GPT-OSS-20B (Ollama) â†’ AI Analysis â†’ Actionable Insights
```

## ğŸ“ Project Structure

```
oss-toy/
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ run.sh             # Quick launch script
â”œâ”€â”€ test_*.py          # Test scripts
â””â”€â”€ data/              # Mock supply chain data
```

## ğŸ” Example Queries

- **Inventory**: "Show me items below reorder point"
- **Deliveries**: "Which deliveries are delayed?"
- **Suppliers**: "Compare supplier performance metrics"
- **Optimization**: "How can we improve warehouse efficiency?"
- **Forecasting**: "Predict next month's inventory needs"

## ğŸ›  Development

- **Add new data sources**: Modify `load_supply_chain_data()`
- **Customize prompts**: Update `generate_prompt()`
- **Add actions**: Extend the action system
- **Model tuning**: Adjust Ollama generation parameters

## ğŸ“Š Demo Data

The app includes realistic mock data:
- 8 items across electronics/accessories categories
- 3 warehouses (NY, LA, Chicago)
- Current inventory levels and reorder points
- 5 active deliveries with various statuses

## ğŸ‰ What Makes This Special

- **Latest AI**: Uses OpenAI's newest open-source model
- **Local & Private**: No data sent to external APIs
- **Real-time**: Streaming AI responses
- **Production Ready**: Error handling, fallbacks, progress indicators
- **Extensible**: Easy to add new features and data sources